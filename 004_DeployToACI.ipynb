{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaec96e",
   "metadata": {},
   "source": [
    "## Deploy a Model to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deploying a model to ACI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe633a",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbb7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.37.0 to work with mm-machine-learning-devops-test\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Model\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff1be16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My current directory is : /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/code-a-thon\n",
      "My directory name is : code-a-thon\n",
      "My user directory name is: memasanz\n",
      "user=memasanz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory_path = os.getcwd()\n",
    "print(\"My current directory is : \" + directory_path)\n",
    "folder_name = os.path.basename(directory_path)\n",
    "print(\"My directory name is : \" + folder_name)\n",
    "\n",
    "parent = os.path.dirname(directory_path)\n",
    "parent_folder_name = os.path.basename(parent)\n",
    "print(\"My user directory name is: \" + parent_folder_name)\n",
    "\n",
    "user = parent_folder_name\n",
    "user = user.replace('_', '')\n",
    "user = user.replace('-', '')\n",
    "user = user[:10]\n",
    "print('user=' + user)\n",
    "experiment_name = parent_folder_name + '-003-code-a-thon-diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7735b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 7\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839b90dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memasanz-004-diabetes_code-a-thon-exp-deploy-aci folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = user + '-004-diabetes_code-a-thon-exp-deploy-aci'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b37bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing memasanz-004-diabetes_code-a-thon-exp-deploy-aci/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    \n",
    "    # Return the predictions as JSON\n",
    "    log_txt = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
    "    print(log_txt)\n",
    "    \n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d397b099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing memasanz-004-diabetes_code-a-thon-exp-deploy-aci/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae1e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memasanz-experiment-env defined.\n",
      "name: experiment_env\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "- scikit-learn\n",
      "- ipykernel\n",
      "- matplotlib\n",
      "- pandas\n",
      "- pip\n",
      "- pip:\n",
      "  - azureml-defaults\n",
      "  - pyarrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(user + \"-experiment-env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7f76a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-03-07 18:58:21+00:00 Creating Container Registry if not exists.\n",
      "2022-03-07 18:58:21+00:00 Registering the environment.\n",
      "2022-03-07 18:58:22+00:00 Use the existing image.\n",
      "2022-03-07 18:58:22+00:00 Generating deployment configuration.\n",
      "2022-03-07 18:58:23+00:00 Submitting deployment to compute.\n",
      "2022-03-07 18:58:25+00:00 Checking the status of deployment diabetes-service..\n",
      "2022-03-07 19:01:58+00:00 Checking the status of inference endpoint diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "inference_config = InferenceConfig(source_directory=experiment_folder,\n",
    "                                   entry_script='score.py',\n",
    "                                   environment=experiment_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, enable_app_insights=True)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d26d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-07T19:00:44,671315700+00:00 - iot-server/run \n",
      "2022-03-07T19:00:44,724578400+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-03-07T19:00:44,739650400+00:00 - rsyslog/run \n",
      "2022-03-07T19:00:44,750320800+00:00 - nginx/run \n",
      "rsyslogd: /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-03-07T19:00:45,135381600+00:00 - iot-server/finish 1 0\n",
      "2022-03-07T19:00:45,141328200+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (69)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 97\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-03-07 19:00:46,530 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-03-07 19:00:46,531 | root | INFO | Starting up request id generator\n",
      "2022-03-07 19:00:46,532 | root | INFO | Starting up app insight hooks\n",
      "2022-03-07 19:00:46,532 | root | INFO | Invoking user's init function\n",
      "2022-03-07 19:00:47,231 | root | INFO | Users's init has completed successfully\n",
      "2022-03-07 19:00:47,234 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2022-03-07 19:00:47,234 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2022-03-07 19:00:47,240 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2022-03-07 19:01:58,703 | root | INFO | Swagger file not present\n",
      "2022-03-07 19:01:58,704 | root | INFO | 404\n",
      "127.0.0.1 - - [07/Mar/2022:19:01:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2022-03-07 19:02:05,096 | root | INFO | Swagger file not present\n",
      "2022-03-07 19:02:05,097 | root | INFO | 404\n",
      "127.0.0.1 - - [07/Mar/2022:19:02:05 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc90124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549102de",
   "metadata": {},
   "source": [
    "You can send multiple observations to the service and get back a perdiction for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea3cf2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] not-diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d24ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d45eccc9-e31e-487d-9edc-06ff2b344857.eastus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3ceb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] not-diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e91818",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
