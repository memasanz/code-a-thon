{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de18b2f8",
   "metadata": {},
   "source": [
    "## Deploy a Model to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2bb70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploying a model to ACI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe633a",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Model\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path = os.getcwd()\n",
    "print(\"My current directory is : \" + directory_path)\n",
    "folder_name = os.path.basename(directory_path)\n",
    "print(\"My directory name is : \" + folder_name)\n",
    "\n",
    "parent = os.path.dirname(directory_path)\n",
    "parent_folder_name = os.path.basename(parent)\n",
    "print(\"My user directory name is: \" + parent_folder_name)\n",
    "\n",
    "user = parent_folder_name\n",
    "user = user.replace('_', '')\n",
    "user = user.replace('-', '')\n",
    "user = user[:10]\n",
    "print('user=' + user)\n",
    "experiment_name = parent_folder_name + '-003-code-a-thon-diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = user + '-004-diabetes_code-a-thon-exp-deploy-aci'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b37bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    \n",
    "    # Return the predictions as JSON\n",
    "    log_txt = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
    "    print(log_txt)\n",
    "    \n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce87955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(user + \"-experiment-env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2251499",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(source_directory=experiment_folder,\n",
    "                                   entry_script='score.py',\n",
    "                                   environment=experiment_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, enable_app_insights=True)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d26d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18698bba",
   "metadata": {},
   "source": [
    "You can send multiple observations to the service and get back a perdiction for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d972302",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
